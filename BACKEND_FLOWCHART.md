# ğŸ—ï¸ AI Chatbot Backend Architecture & Flow Documentation

## ğŸ“‹ Table of Contents
1. [System Overview](#system-overview)
2. [Complete Architecture Diagram](#complete-architecture-diagram)
3. [Component Details](#component-details)
4. [Data Flow Diagrams](#data-flow-diagrams)
5. [RAG Pipeline](#rag-pipeline)
6. [API Endpoints](#api-endpoints)
7. [Database Schema](#database-schema)

---

## ğŸ¯ System Overview

The AI Chatbot Backend is a Spring Boot application that provides intelligent assistance for IBM Maximo Application Suite using **RAG (Retrieval-Augmented Generation)** technology.

### Key Technologies
- **Spring Boot 3.2.0** - Application framework
- **Ollama (Granite 4:micro-h)** - AI model for response generation ONLY (no embeddings)
- **MongoDB** - Chat history and execution logs
- **File-based Text Chunk Store** - Document text chunks (NOT vector embeddings)
- **Keyword-Based Semantic Search** - Heuristic scoring with synonym expansion
- **GitHub API** - Knowledge base repository access

---

## ğŸ”„ Complete Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           USER INTERACTION LAYER                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     HTTP (Port 3000)     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚  React Frontend â”‚ â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚  Chat Interface    â”‚         â”‚
â”‚  â”‚  (Vite + Carbon)â”‚                          â”‚ Execution Console  â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚           â”‚                                              â”‚                   â”‚
â”‚           â”‚ REST API (JSON)                              â”‚                   â”‚
â”‚           â–¼                                              â–¼                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                                              â”‚
            â”‚                        HTTP (Port 8080)      â”‚
            â”‚                                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          BACKEND APPLICATION LAYER                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚                        CONTROLLER LAYER                             â”‚     â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”‚
â”‚  â”‚                                                                     â”‚     â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚     â”‚
â”‚  â”‚  â”‚ChatControllerâ”‚  â”‚AdminControll â”‚  â”‚GitHubCtrl  â”‚  â”‚HealthCtrlâ”‚   â”‚     â”‚
â”‚  â”‚  â”‚POST /message â”‚  â”‚GET  /repos   â”‚  â”‚GET /file   â”‚  â”‚GET /     â”‚   â”‚     â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â”‚     â”‚
â”‚  â”‚         â”‚                  â”‚                 â”‚              â”‚       â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚            â”‚                  â”‚                 â”‚              â”‚             â”‚
â”‚            â–¼                  â–¼                 â–¼              â–¼             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚                         SERVICE LAYER                               â”‚     â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”‚
â”‚  â”‚                                                                     â”‚     â”‚ 
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚     â”‚
â”‚  â”‚  â”‚  ChatService  â”‚ â—„â”€â”€â”€â”€â”€â”€â”¤DocumentProcessingâ”œâ”€â”€â”€â”€â–º â”‚RAGService  â”‚  â”‚     â”‚
â”‚  â”‚  â”‚   (Orchestrator)       â”‚     Service      â”‚      â”‚            â”‚  â”‚     â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚     â”‚
â”‚  â”‚          â”‚                                                          â”‚     â”‚
â”‚  â”‚          â”‚                                                          â”‚     â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚     â”‚
â”‚  â”‚  â”‚ OllamaService  â”‚      â”‚  GitHubService   â”‚      â”‚UserService â”‚   â”‚     â”‚
â”‚  â”‚  â”‚ (AI Generation)â”‚      â”‚  (Repo Access)   â”‚      â”‚(Auth)      â”‚   â”‚     â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚     â”‚
â”‚  â”‚                                                                     â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                             â”‚                       â”‚                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚                       â”‚
                              â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          DATA PERSISTENCE LAYER                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚  MongoDB (Port 27017)â”‚              â”‚  File-Based Storage  â”‚             â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤              â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤             â”‚
â”‚  â”‚ â€¢ ChatHistory        â”‚              â”‚ â€¢ embeddings.jsonl   â”‚             â”‚
â”‚  â”‚ â€¢ ExecutionHistory   â”‚              â”‚ â€¢ Plain Text Chunks  â”‚             â”‚
â”‚  â”‚ â€¢ Users              â”‚              â”‚ â€¢ NO Vector Data     â”‚             â”‚
â”‚  â”‚ â€¢ Pipelines          â”‚              â”‚ â€¢ Metadata Only      â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       EXTERNAL SERVICES LAYER                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚ Ollama (Port 11434)  â”‚              â”‚  GitHub API          â”‚             â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤              â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤             â”‚
â”‚  â”‚ â€¢ Granite 4:micro-h  â”‚              â”‚ â€¢ github.ibm.com     â”‚             â”‚
â”‚  â”‚ â€¢ Text Generation    â”‚              â”‚ â€¢ Repository Access  â”‚             â”‚
â”‚  â”‚ â€¢ Chat Responses ONLYâ”‚              â”‚ â€¢ File Retrieval     â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ Component Details

### 1. **Controller Layer** (Entry Points)

#### `ChatController.java`
```
Purpose: Handle chat API requests
Endpoint: POST /api/chat/message
Flow:
  1. Receive ChatRequest (message, sessionId, includeContext, fastMode)
  2. Validate request
  3. Call ChatService.processMessage()
  4. Return ChatResponse (response, sources, timing, model)
```

#### `GitHubController.java`
```
Purpose: Fetch raw file content from GitHub
Endpoint: GET /api/github/file?url={githubUrl}
Flow:
  1. Parse GitHub URL
  2. Extract repo, branch, path
  3. Call GitHub API
  4. Return file content
```

#### `HealthController.java`
```
Purpose: System health monitoring
Endpoint: GET /api/health
Returns:
  - Application status
  - Ollama connectivity
  - MongoDB connectivity
  - Embedding count
```

---

### 2. **Service Layer** (Business Logic)

#### `ChatService.java` â­ CORE ORCHESTRATOR

**Purpose:** Orchestrates the entire chat processing workflow

**Key Methods:**

##### `processMessage(ChatRequest)`
```java
/**
 * Main entry point for chat processing
 * 
 * Flow:
 * 1. Check if direct file request â†’ handleDirectFileRequest()
 * 2. Retrieve context using DocumentProcessingService:
 *    - fullContent=true  â†’ findBestMatchingFile() (entire file)
 *    - fullContent=false â†’ findSimilarDocumentsHybrid() (specific chunks)
 * 3. Apply fallback chain:
 *    - Hybrid search
 *    - Best file approach
 *    - Standard search
 *    - Keyword search
 * 4. Build contextual prompt â†’ buildContextualPrompt()
 * 5. Generate AI response â†’ OllamaService.generateResponse()
 * 6. Return ChatResponse with metadata
 * 
 * @param request ChatRequest containing user message and options
 * @return CompletableFuture<ChatResponse> Async response with AI answer
 */
```

##### `buildContextualPrompt(String query, List<DocumentEmbedding> chunks)`
```java
/**
 * Constructs intelligent prompt for AI based on query intent
 * 
 * Smart Features:
 * 1. Detect "create X" queries â†’ Extract only Prerequisites + Create section
 * 2. Detect "raw/exact" requests â†’ Return complete unmodified content
 * 3. Detect prerequisites â†’ Show prerequisites first, then answer
 * 4. Standard queries â†’ Extract only relevant sections
 * 
 * Slicing Logic:
 * - extractPrerequisites() â†’ Finds "Prerequisites" heading
 * - extractOperationSection("create") â†’ Finds "Create" section
 * - Combines both for targeted response
 * 
 * @param query User's question
 * @param chunks Retrieved document chunks
 * @return Formatted prompt for AI model
 */
```

##### `extractOperationSection(String content, String operation)`
```java
/**
 * Extracts specific operation section from markdown documentation
 * 
 * Search Order:
 * 1. Numbered headings: "## 1. Create Asset"
 * 2. Unnumbered headings: "## Create Asset"
 * 3. Any level heading: "### Create Asset"
 * 
 * Uses regex to capture from heading until next heading or EOF
 * 
 * @param content Full document content
 * @param operation Operation name (create/query/update/delete)
 * @return Extracted section or null
 */
```

---

#### `DocumentProcessingService.java` â­ CORE RETRIEVAL ENGINE

**Purpose:** Manage document text chunks and keyword-based semantic search

**Key Methods:**

##### `findRelevantChunks(String query, int maxResults)`
```java
/**
 * Keyword-based search with semantic expansion and heuristic scoring
 * 
 * Algorithm:
 * 1. Calculate relevance score for all text chunks using:
 *    - Exact word matching (highest weight)
 *    - Partial word matching
 *    - Phrase proximity scoring
 *    - Filename matching bonus
 *    - Semantic keyword expansion (synonyms)
 * 2. Filter by minimum score threshold (0.1)
 * 3. Sort by relevance score (descending)
 * 4. Return top N results
 * 
 * NO VECTOR EMBEDDINGS - Pure keyword/heuristic approach
 * 
 * @param query User's search query
 * @param maxResults Maximum chunks to return
 * @return List of relevant document chunks
 */
```

##### `findBestMatchingFile(String query)`
```java
/**
 * Returns ALL chunks from the single best matching file
 * 
 * Use Case: Complete guides, installation steps, full documentation
 * 
 * Algorithm:
 * 1. Score all files using Top-K chunk averaging:
 *    - Calculate relevance score for each chunk in file
 *    - Take top 5 chunk scores per file
 *    - Average top-5 scores as file-level score
 * 2. Add filename matching bonus
 * 3. Select file with highest total score
 * 4. Return ALL chunks from that file (sorted by index)
 * 
 * NO EMBEDDINGS - Uses keyword-based scoring
 * 
 * @param query User's search query
 * @return All chunks from best matching file
 */
```

##### `processDocument(String filePath, String content, String owner, String name, String branch)`
```java
/**
 * Processes GitHub document to create text chunks (NOT embeddings)
 * 
 * Flow:
 * 1. Split content into chunks (~3000 chars max)
 *    - Splits by paragraphs (\n\n)
 *    - If too long, splits by sentences
 *    - Maintains readability
 * 2. Create DocumentEmbedding objects (misnomer - just text storage)
 * 3. Save to file: data/embeddings/embeddings.jsonl
 * 4. Cache in memory for fast retrieval
 * 
 * NO OLLAMA INVOLVEMENT - Just text chunking and storage
 * 
 * @param filePath Source file path
 * @param content Raw text content
 * @param owner Repository owner
 * @param name Repository name
 * @param branch Branch name
 */
```

---

#### `OllamaService.java` â­ AI INTEGRATION

**Purpose:** Interface with Ollama AI model

**Key Methods:**

##### `generateResponse(String prompt)`
```java
/**
 * Generates AI response using Ollama Granite 4:micro-h model
 * 
 * Configuration:
 * - Model: granite4:micro-h (fast, accurate)
 * - Temperature: 0.7 (balanced creativity)
 * - Max Tokens: 4096
 * 
 * Connection:
 * - URL: http://localhost:11434
 * - Protocol: HTTP POST
 * - Format: JSON
 * 
 * @param prompt Contextual prompt with user query + retrieved docs
 * @return AI-generated response text
 */
```

##### `isHealthy()`
```java
/**
 * Checks if Ollama service is accessible
 * 
 * Calls GET /api/tags endpoint to verify connectivity
 * 
 * NOTE: Ollama is ONLY used for chat response generation,
 * NOT for embeddings or semantic search.
 * 
 * @return boolean indicating service health
 */
```

---

#### `GitHubService.java` ğŸ“š KNOWLEDGE BASE ACCESS

**Purpose:** Fetch documentation from GitHub repositories

**Key Methods:**

##### `fetchFileContent(String owner, String repo, String path, String branch)`
```java
/**
 * Retrieves file content from GitHub
 * 
 * Supports:
 * - github.com (public)
 * - github.ibm.com (enterprise)
 * 
 * Authentication: Personal Access Token (PAT)
 * 
 * @param owner Repository owner
 * @param repo Repository name
 * @param path File path
 * @param branch Branch name
 * @return File content as string
 */
```

##### `listMarkdownFiles(String owner, String repo, String branch)`
```java
/**
 * Recursively lists all markdown files in repository
 * 
 * Filters:
 * - Only .md files
 * - Excludes: README, LICENSE, CHANGELOG
 * 
 * @return List of file paths
 */
```

---

### 3. **Model Layer** (Data Structures)

#### `DocumentEmbedding.java`
```java
/**
 * Represents a document text chunk (NOT actual embeddings!)
 * 
 * IMPORTANT: Despite the name, this class does NOT store vector embeddings.
 * It only stores plain text chunks with metadata.
 * 
 * Fields:
 * - id: Unique identifier
 * - filePath: Source file path
 * - contentChunk: Raw text content (~3000 chars)
 * - chunkIndex: Position in original file
 * - repositoryOwner: Repository owner
 * - repositoryName: Repository name
 * - branchName: Branch name
 * - createdAt: Timestamp
 * 
 * NO VECTOR FIELD EXISTS - Search uses keyword matching on contentChunk
 * 
 * Stored in: backend/data/embeddings/embeddings.jsonl
 */
```

#### `ChatMessage.java`
```java
/**
 * Represents a chat message
 * 
 * Fields:
 * - id: Message ID
 * - sessionId: Conversation session
 * - userMessage: User's question
 * - assistantResponse: AI's answer
 * - sourceFiles: Referenced documents
 * - timestamp: Message time
 * - modelUsed: AI model name
 * 
 * Stored in: MongoDB chatHistory collection
 */
```

---

## ğŸ”„ Data Flow Diagrams

### Complete Request Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     CHAT REQUEST PROCESSING FLOW                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. USER SENDS MESSAGE
   â”‚
   â”œâ”€â–º Frontend: React Chat Interface
   â”‚   â€¢ User types: "create asset"
   â”‚   â€¢ Click Send button
   â”‚
   â–¼

2. HTTP REQUEST TO BACKEND
   â”‚
   â”œâ”€â–º POST /api/chat/message
   â”‚   Content-Type: application/json
   â”‚   {
   â”‚     "message": "create asset",
   â”‚     "sessionId": "web-session-123",
   â”‚     "includeContext": true,
   â”‚     "fastMode": true,
   â”‚     "fullContent": true
   â”‚   }
   â”‚
   â–¼

3. CONTROLLER LAYER
   â”‚
   â”œâ”€â–º ChatController.sendMessage()
   â”‚   â€¢ Validate request
   â”‚   â€¢ Log request
   â”‚   â€¢ Call service layer
   â”‚
   â–¼

4. SERVICE ORCHESTRATION
   â”‚
   â”œâ”€â–º ChatService.processMessage()
   â”‚   â”‚
   â”‚   â”œâ”€â–º Step 1: Check if direct file request
   â”‚   â”‚   â€¢ Pattern match: ".md", "raw", "exact"
   â”‚   â”‚   â€¢ If yes â†’ Skip RAG, return raw file
   â”‚   â”‚   â€¢ If no â†’ Continue to RAG pipeline
   â”‚   â”‚
   â”‚   â”œâ”€â–º Step 2: Retrieve context (RAG Pipeline)
   â”‚   â”‚   â”‚
   â”‚   â”‚   â”œâ”€â–º DocumentProcessingService.findBestMatchingFile()
   â”‚   â”‚   â”‚   â”‚
   â”‚   â”‚   â”‚   â”œâ”€â–º Calculate similarity scores for all files
   â”‚   â”‚   â”‚   â”‚   â€¢ Query embedding: [0.234, 0.567, ...]
   â”‚   â”‚   â”‚   â”‚   â€¢ Compare with file embeddings
   â”‚   â”‚   â”‚   â”‚   â€¢ Cosine similarity calculation
   â”‚   â”‚   â”‚   â”‚
   â”‚   â”‚   â”‚   â”œâ”€â–º Select file with highest average score
   â”‚   â”‚   â”‚   â”‚   â€¢ Assets_API_Guide.md: 0.85
   â”‚   â”‚   â”‚   â”‚   â€¢ DB2_Setup.md: 0.42
   â”‚   â”‚   â”‚   â”‚   â€¢ Winner: Assets_API_Guide.md
   â”‚   â”‚   â”‚   â”‚
   â”‚   â”‚   â”‚   â””â”€â–º Return ALL chunks from best file
   â”‚   â”‚   â”‚       â€¢ Chunk 0: "# Assets API..."
   â”‚   â”‚   â”‚       â€¢ Chunk 1: "## Prerequisites..."
   â”‚   â”‚   â”‚       â€¢ Chunk 2: "## Create Asset..."
   â”‚   â”‚   â”‚       â€¢ Total: 15 chunks
   â”‚   â”‚   â”‚
   â”‚   â”‚   â””â”€â–º Result: 15 DocumentEmbedding objects
   â”‚   â”‚
   â”‚   â”œâ”€â–º Step 3: Build contextual prompt
   â”‚   â”‚   â”‚
   â”‚   â”‚   â”œâ”€â–º Detect query intent: "create"
   â”‚   â”‚   â”‚
   â”‚   â”‚   â”œâ”€â–º Extract prerequisites section
   â”‚   â”‚   â”‚   â€¢ Regex: "## Prerequisite..."
   â”‚   â”‚   â”‚   â€¢ Result: "Valid API key required..."
   â”‚   â”‚   â”‚
   â”‚   â”‚   â”œâ”€â–º Extract create section
   â”‚   â”‚   â”‚   â€¢ Regex: "## Create Asset"
   â”‚   â”‚   â”‚   â€¢ Result: "Method: POST, URL: /MXAPIASSET..."
   â”‚   â”‚   â”‚
   â”‚   â”‚   â””â”€â–º Combine into prompt:
   â”‚   â”‚       "Return EXACT content for: create asset
   â”‚   â”‚        CONTENT:
   â”‚   â”‚        ## Prerequisites
   â”‚   â”‚        ...
   â”‚   â”‚        ## Create Asset
   â”‚   â”‚        Method: POST
   â”‚   â”‚        URL: /MXAPIASSET
   â”‚   â”‚        Headers: apikey: <your-apikey-value>
   â”‚   â”‚        Parameters: lean: 1
   â”‚   â”‚        ..."
   â”‚   â”‚
   â”‚   â”œâ”€â–º Step 4: Generate AI response
   â”‚   â”‚   â”‚
   â”‚   â”‚   â”œâ”€â–º OllamaService.generateResponse(prompt)
   â”‚   â”‚   â”‚   â”‚
   â”‚   â”‚   â”‚   â”œâ”€â–º HTTP POST to Ollama
   â”‚   â”‚   â”‚   â”‚   URL: http://localhost:11434/api/generate
   â”‚   â”‚   â”‚   â”‚   Model: granite4:micro-h
   â”‚   â”‚   â”‚   â”‚   Prompt: [contextual prompt from above]
   â”‚   â”‚   â”‚   â”‚
   â”‚   â”‚   â”‚   â””â”€â–º AI processes and returns:
   â”‚   â”‚   â”‚       "## Prerequisites
   â”‚   â”‚   â”‚        - Valid API key
   â”‚   â”‚   â”‚        
   â”‚   â”‚   â”‚        ## Create Asset
   â”‚   â”‚   â”‚        Method: POST
   â”‚   â”‚   â”‚        URL: /MXAPIASSET
   â”‚   â”‚   â”‚        Headers: apikey: <your-apikey-value>
   â”‚   â”‚   â”‚        Parameters: lean: 1
   â”‚   â”‚   â”‚        Request Body: {...}"
   â”‚   â”‚   â”‚
   â”‚   â”‚   â””â”€â–º Response received in <2 seconds
   â”‚   â”‚
   â”‚   â””â”€â–º Step 5: Package response
   â”‚       â€¢ response: AI-generated text
   â”‚       â€¢ sessionId: "web-session-123"
   â”‚       â€¢ responseTime: 1847ms
   â”‚       â€¢ sourceFiles: ["Assets API Guide"]
   â”‚       â€¢ modelUsed: "granite4:micro-h"
   â”‚
   â–¼

5. RETURN TO FRONTEND
   â”‚
   â”œâ”€â–º ChatResponse JSON:
   â”‚   {
   â”‚     "response": "## Prerequisites...",
   â”‚     "sessionId": "web-session-123",
   â”‚     "responseTime": 1847,
   â”‚     "sourceFiles": ["Assets API Guide"],
   â”‚     "modelUsed": "granite4:micro-h",
   â”‚     "success": true
   â”‚   }
   â”‚
   â–¼

6. FRONTEND RENDERS
   â”‚
   â”œâ”€â–º Parse markdown
   â”œâ”€â–º Extract execution details:
   â”‚   â€¢ Method: POST
   â”‚   â€¢ URL: /MXAPIASSET
   â”‚   â€¢ Headers: apikey: <your-apikey-value>
   â”‚   â€¢ Parameters: lean: 1
   â”‚   â€¢ Body: {...}
   â”‚
   â””â”€â–º Display with "Execute" button
       User can click to open Execution Console
```

---

## ğŸ§  RAG Pipeline Detailed Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               RETRIEVAL-AUGMENTED GENERATION (RAG) PIPELINE              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

PHASE 1: DOCUMENT INDEXING (Startup / Scheduled)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ System Startup  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DocumentProcessingService.init()    â”‚
â”‚ @PostConstruct                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â–º Load repositories from config
         â”‚   â€¢ Repo 1: maximo-application-suite/knowledge-center
         â”‚   â€¢ Repo 2: maximo-application-suite/api-docs
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ For each repository:                â”‚
â”‚ processRepository(repo)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â–º Step 1: Fetch files from GitHub
         â”‚   â”‚
         â”‚   â”œâ”€â–º GitHubService.listMarkdownFiles()
         â”‚   â”‚   â€¢ GET /repos/{owner}/{repo}/git/trees/{branch}?recursive=1
         â”‚   â”‚   â€¢ Filter: *.md files only
         â”‚   â”‚   â€¢ Result: [install.md, api.md, setup.md, ...]
         â”‚   â”‚
         â”‚   â””â”€â–º GitHubService.fetchFileContent(file)
         â”‚       â€¢ GET /repos/{owner}/{repo}/contents/{path}?ref={branch}
         â”‚       â€¢ Decode base64 content
         â”‚       â€¢ Result: Raw markdown text
         â”‚
         â”œâ”€â–º Step 2: Split into chunks
         â”‚   â”‚
         â”‚   â”œâ”€â–º For each file:
         â”‚   â”‚   â€¢ Max chunk size: 5000 characters
         â”‚   â”‚   â€¢ Preserve paragraph boundaries
         â”‚   â”‚   â€¢ Maintain context overlap: 200 chars
         â”‚   â”‚
         â”‚   â””â”€â–º Result: Multiple chunks per file
         â”‚       â€¢ install.md â†’ 8 chunks
         â”‚       â€¢ api.md â†’ 12 chunks
         â”‚
         â”œâ”€â–º Step 3: Create text chunk objects (NO EMBEDDING GENERATION)
         â”‚   â”‚
         â”‚   â”œâ”€â–º For each chunk:
         â”‚   â”‚   new DocumentEmbedding()
         â”‚   â”‚   â”‚
         â”‚   â”‚   â”œâ”€â–º setFilePath("install.md")
         â”‚   â”‚   â”œâ”€â–º setContentChunk("Prerequisites for...")
         â”‚   â”‚   â”œâ”€â–º setChunkIndex(0)
         â”‚   â”‚   â”œâ”€â–º setRepositoryOwner("maximo-application-suite")
         â”‚   â”‚   â”œâ”€â–º setRepositoryName("knowledge-center")
         â”‚   â”‚   â””â”€â–º setCreatedAt(LocalDateTime.now())
         â”‚   â”‚
         â”‚   â”‚   âŒ NO OLLAMA API CALL
         â”‚   â”‚   âŒ NO VECTOR GENERATION
         â”‚   â”‚   âœ… JUST PLAIN TEXT STORAGE
         â”‚   â”‚
         â”‚   â””â”€â–º Store DocumentEmbedding:
         â”‚       {
         â”‚         "id": "uuid-123",
         â”‚         "filePath": "install.md",
         â”‚         "contentChunk": "Prerequisites for...",
         â”‚         "chunkIndex": 0,
         â”‚         "repositoryOwner": "maximo-application-suite",
         â”‚         "repositoryName": "knowledge-center",
         â”‚         "branchName": "main"
         â”‚       }
         â”‚       
         â”‚       âŒ NO "embedding" field - just text!
         â”‚
         â””â”€â–º Step 4: Persist text chunks
             â”‚
             â”œâ”€â–º Save to file: backend/data/embeddings/embeddings.jsonl
             â”‚   â€¢ One JSON object per line (JSONL format)
             â”‚   â€¢ Contains plain text chunks + metadata
             â”‚   â€¢ NO vector data stored
             â”‚   â€¢ Total size: ~5-10 MB for 159 chunks
             â”‚
             â””â”€â–º Cache in memory: CopyOnWriteArrayList
                 â€¢ All chunks loaded into memory on startup
                 â€¢ Fast iteration for keyword search
                 â€¢ FileEmbeddingStore.findAll() returns all chunks


PHASE 2: QUERY PROCESSING (User Request)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User Query:     â”‚
â”‚ "create asset"  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ChatService.processMessage()        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â–º Prepare query (NO EMBEDDING GENERATION)
         â”‚   â”‚
         â”‚   â”œâ”€â–º Normalize query: "create asset" â†’ ["create", "asset"]
         â”‚   â”‚
         â”‚   â””â”€â–º Expand keywords with synonyms:
         â”‚       â€¢ "create" â†’ ["create", "creating", "setup", "configure", "build"]
         â”‚       â€¢ "asset" â†’ ["asset", "assets"]
         â”‚
         â”œâ”€â–º Find similar documents using KEYWORD SEARCH
         â”‚   â”‚
         â”‚   â”œâ”€â–º DocumentProcessingService.findBestMatchingFile()
         â”‚   â”‚   â”‚
         â”‚   â”‚   â”œâ”€â–º Algorithm: Keyword-based file-level scoring
         â”‚   â”‚   â”‚   â”‚
         â”‚   â”‚   â”‚   â”œâ”€â–º For each unique file:
         â”‚   â”‚   â”‚   â”‚   â€¢ Get all chunks from file
         â”‚   â”‚   â”‚   â”‚   â€¢ Calculate relevance score for each chunk:
         â”‚   â”‚   â”‚   â”‚     score = calculateRelevanceScore(
         â”‚   â”‚   â”‚   â”‚       contentChunk, filePath, queryWords, fullQuery
         â”‚   â”‚   â”‚   â”‚     )
         â”‚   â”‚   â”‚   â”‚     Scoring factors:
         â”‚   â”‚   â”‚   â”‚     - Exact word matches: +15 points
         â”‚   â”‚   â”‚   â”‚     - Partial word matches: +8 points
         â”‚   â”‚   â”‚   â”‚     - Exact phrase match: +50 points
         â”‚   â”‚   â”‚   â”‚     - Word proximity bonus: +25 points
         â”‚   â”‚   â”‚   â”‚     - Filename matches: +3 points
         â”‚   â”‚   â”‚   â”‚     - Semantic bonuses: +30-60 points
         â”‚   â”‚   â”‚   â”‚   â€¢ Sort chunk scores (descending)
         â”‚   â”‚   â”‚   â”‚   â€¢ Take top-5 chunk scores
         â”‚   â”‚   â”‚   â”‚   â€¢ fileScore = average(top-5 scores)
         â”‚   â”‚   â”‚   â”‚
         â”‚   â”‚   â”‚   â”œâ”€â–º Sort files by score (descending)
         â”‚   â”‚   â”‚   â”‚   â€¢ Assets_API_Guide.md: 85.4
         â”‚   â”‚   â”‚   â”‚   â€¢ DB2_Setup.md: 12.3
         â”‚   â”‚   â”‚   â”‚   â€¢ Install_Guide.md: 8.7
         â”‚   â”‚   â”‚   â”‚
         â”‚   â”‚   â”‚   â””â”€â–º Select best file: Assets_API_Guide.md
         â”‚   â”‚   â”‚
         â”‚   â”‚   â””â”€â–º Return ALL chunks from best file (sorted by index)
         â”‚   â”‚       â€¢ Total: 15 chunks
         â”‚   â”‚       â€¢ Content: Complete API guide
         â”‚   â”‚
         â”‚   â””â”€â–º Result: List<DocumentEmbedding> (15 items)
         â”‚       
         â”‚       âŒ NO VECTOR SIMILARITY
         â”‚       âœ… PURE KEYWORD MATCHING + HEURISTICS
         â”‚
         â””â”€â–º Build contextual prompt
             â”‚
             â”œâ”€â–º Combine chunks into context
             â”‚   â€¢ Join all chunk content
             â”‚   â€¢ Detect prerequisites section
             â”‚   â€¢ Detect create section
             â”‚   â€¢ Slice to relevant parts only
             â”‚
             â””â”€â–º Format for AI:
                 "USER QUESTION: create asset
                  CONTENT:
                  ## Prerequisites
                  - Valid API key required
                  
                  ## Create Asset
                  Method: POST
                  URL: /MXAPIASSET
                  Headers: apikey: <your-apikey-value>
                  Parameters: lean: 1
                  Request Body: {...}
                  
                  RETURN EXACT CONTENT FOR: create asset"


PHASE 3: AI GENERATION (Ollama)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OllamaService.generateResponse()    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â–º HTTP POST to Ollama
         â”‚   â”‚
         â”‚   â”œâ”€â–º URL: http://localhost:11434/api/generate
         â”‚   â”‚
         â”‚   â”œâ”€â–º Request Body:
         â”‚   â”‚   {
         â”‚   â”‚     "model": "granite4:micro-h",
         â”‚   â”‚     "prompt": "[contextual prompt]",
         â”‚   â”‚     "stream": false,
         â”‚   â”‚     "options": {
         â”‚   â”‚       "temperature": 0.7,
         â”‚   â”‚       "num_predict": 4096
         â”‚   â”‚     }
         â”‚   â”‚   }
         â”‚   â”‚
         â”‚   â””â”€â–º Ollama Processing:
         â”‚       â€¢ Load model: granite4:micro-h
         â”‚       â€¢ Tokenize prompt
         â”‚       â€¢ Generate response tokens
         â”‚       â€¢ Decode to text
         â”‚       â€¢ Time: ~1-2 seconds
         â”‚
         â””â”€â–º Response:
             {
               "model": "granite4:micro-h",
               "created_at": "2024-11-20T10:30:00Z",
               "response": "## Prerequisites\n- Valid API key...\n\n## Create Asset\nMethod: POST...",
               "done": true
             }


PHASE 4: RESPONSE ASSEMBLY
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ChatService assembles final responseâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â–º Extract metadata
         â”‚   â€¢ Response time: 1847ms
         â”‚   â€¢ Source files: ["Assets API Guide"]
         â”‚   â€¢ Model used: "granite4:micro-h"
         â”‚
         â””â”€â–º Return ChatResponse
             {
               "response": "[AI-generated text]",
               "sessionId": "web-session-123",
               "responseTime": 1847,
               "sourceFiles": ["Assets API Guide"],
               "modelUsed": "granite4:micro-h",
               "success": true
             }
```

---

## ğŸ”Œ API Endpoints Reference

### Chat Endpoints

#### `POST /api/chat/message`
**Purpose:** Send a message and get AI response

**Request:**
```json
{
  "message": "create asset",
  "sessionId": "web-session-123",
  "includeContext": true,
  "fastMode": true,
  "fullContent": true
}
```

**Response:**
```json
{
  "response": "## Prerequisites\n...\n## Create Asset\n...",
  "sessionId": "web-session-123",
  "responseTime": 1847,
  "sourceFiles": ["Assets API Guide"],
  "modelUsed": "granite4:micro-h",
  "success": true
}
```

---

### Health Endpoints

#### `GET /api/health`
**Purpose:** Check system health

**Response:**
```json
{
  "status": "UP",
  "ollama": {
    "status": "UP",
    "model": "granite4:micro-h",
    "url": "http://localhost:11434"
  },
  "mongodb": {
    "status": "UP",
    "url": "mongodb://localhost:27017"
  },
  "embeddings": {
    "count": 159,
    "lastIndexed": "2024-11-20T09:15:00Z"
  }
}
```

---

## ğŸ—„ï¸ Database Schema

### MongoDB Collections

#### `chatHistory`
```javascript
{
  _id: ObjectId("..."),
  id: "uuid-123",
  username: "john.doe",
  title: "Create Asset Discussion",
  createdAt: ISODate("2024-11-20T10:30:00Z"),
  messages: [
    {
      id: "msg-1",
      type: "user",
      content: "create asset",
      timestamp: ISODate("2024-11-20T10:30:00Z")
    },
    {
      id: "msg-2",
      type: "assistant",
      content: "## Prerequisites...",
      sourceFiles: ["Assets API Guide"],
      timestamp: ISODate("2024-11-20T10:30:02Z")
    }
  ]
}
```

#### `executionHistory`
```javascript
{
  _id: ObjectId("..."),
  id: "exec-456",
  username: "john.doe",
  actionTitle: "Create Asset",
  method: "POST",
  url: "/MXAPIASSET",
  requestHeaders: [
    { key: "apikey", value: "xxx" },
    { key: "Content-Type", value: "application/json" }
  ],
  requestParams: [
    { key: "lean", value: "1" }
  ],
  requestBody: "{...}",
  responseStatus: 201,
  responseBody: "{...}",
  timestamp: ISODate("2024-11-20T10:35:00Z"),
  duration: 245
}
```

#### `users`
```javascript
{
  _id: ObjectId("..."),
  username: "john.doe",
  email: "john@example.com",
  role: "user",
  createdAt: ISODate("2024-11-01T00:00:00Z"),
  lastLogin: ISODate("2024-11-20T10:00:00Z")
}
```

---

### File-Based Storage

#### `backend/data/embeddings/embeddings.jsonl`
```json
{"id":"uuid-1","filePath":"Assets_API_Guide.md","contentChunk":"# Assets API...\n\nThis guide covers...","chunkIndex":0,"repositoryOwner":"maximo-application-suite","repositoryName":"knowledge-center","branchName":"main","createdAt":"2024-11-20T09:15:00Z","updatedAt":"2024-11-20T09:15:00Z"}
{"id":"uuid-2","filePath":"Assets_API_Guide.md","contentChunk":"## Prerequisites\n\n- Valid API key\n- Maximo instance...","chunkIndex":1,"repositoryOwner":"maximo-application-suite","repositoryName":"knowledge-center","branchName":"main","createdAt":"2024-11-20T09:15:00Z","updatedAt":"2024-11-20T09:15:00Z"}
```

**Format:** JSON Lines (one object per line)
**Content:** Plain text chunks ONLY (no vector data)
**Size:** ~5-10 MB (159 text chunks)
**Loading:** On startup into CopyOnWriteArrayList via FileEmbeddingStore
**Search:** Keyword-based iteration through all chunks (no vector similarity)

---

## ğŸ¯ Key Design Decisions

### Why Keyword-Based Search (No Vector Embeddings)?
- **Simplicity:** No ML model dependencies or vector database
- **Performance:** Fast in-memory keyword matching with heuristic scoring
- **Transparency:** Scoring logic is explainable and debuggable
- **Efficiency:** No embedding generation overhead (Ollama only for chat)
- **Accuracy:** Semantic expansion with synonyms provides intelligent matching
- **Cost:** Zero additional infrastructure or API calls

### Why File-Based Text Chunk Storage?
- **Simplicity:** No vector database setup required
- **Performance:** In-memory array provides fast iteration
- **Portability:** Easy to backup, version, and deploy (JSONL format)
- **Lightweight:** ~5-10 MB vs 50+ MB for vector embeddings

### Why Heuristic Scoring (Instead of Vector Similarity)?
- **Speed:** No cosine similarity calculations needed
- **Control:** Fine-tune scoring weights for domain-specific needs
- **Reliability:** Consistent results without model dependencies
- **Flexibility:** Easy to add custom bonuses for specific query patterns

### Why Smart Slicing?
- **Precision:** Returns only relevant sections (not entire files)
- **Speed:** Smaller prompts = faster AI responses
- **User Experience:** Users get exactly what they asked for

### Why Multiple Fallbacks?
- **Reliability:** System works even if one method fails
- **Comprehensive Coverage:** Different queries need different approaches
- **Zero Empty Responses:** Always finds something relevant

---

## ğŸ“Š Performance Metrics

| Operation | Time | Details |
|-----------|------|---------||
| Query Normalization | <1ms | String processing |
| Keyword Search | 50-150ms | In-memory iteration with scoring |
| File Matching | 100-200ms | Multi-file Top-K scoring |
| AI Response Generation | 1-2s | Ollama Granite 4:micro-h (chat only) |
| **Total Response Time** | **1.2-2.5s** | End-to-end |

| Resource | Usage | Limits |
|----------|-------|--------|
| Text Chunks in Memory | ~10-15 MB | 159 plain text chunks |
| MongoDB Storage | ~10 MB | Chat + execution history |
| Ollama Memory | ~4 GB | Model loaded (chat only) |
| Backend Memory | ~256 MB | Spring Boot + text cache |

---

## ğŸ”’ Security Considerations

1. **GitHub Token**: Stored in environment variable, never exposed to frontend
2. **MongoDB**: No authentication in development (add in production)
3. **CORS**: Configured for localhost:3000 (update for production)
4. **File Paths**: Sanitized before returning to frontend
5. **API Keys**: Placeholder values in responses

---

## ğŸš€ Deployment Architecture

```
Production Environment:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Cloud Platform                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Frontend    â”‚   â”‚  Backend     â”‚   â”‚  Ollama      â”‚     â”‚
â”‚  â”‚  (React)     â”‚   â”‚  (Spring)    â”‚   â”‚  (AI Model)  â”‚     â”‚
â”‚  â”‚  Port 80/443 â”‚   â”‚  Port 8080   â”‚   â”‚  Port 11434  â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚         â”‚                  â”‚                  â”‚             â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                            â”‚                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              MongoDB Atlas (Managed)                 â”‚   â”‚
â”‚  â”‚              - Chat History                          â”‚   â”‚
â”‚  â”‚              - Execution Logs                        â”‚   â”‚
â”‚  â”‚              - User Data                             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---



---

**Last Updated:** November 20, 2024  
**Version:** 1.0.0  
**Maintainer:** Shreyas Gowda
